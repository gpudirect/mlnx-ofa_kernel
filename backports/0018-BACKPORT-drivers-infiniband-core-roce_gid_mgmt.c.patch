From: Alaa Hleihel <alaa@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/infiniband/core/roce_gid_mgmt.c

Change-Id: I1a37633c9482a328e2f1f8e4ab7c054a4c4bb5d2
---
 drivers/infiniband/core/roce_gid_mgmt.c | 123 +++++++++++++++++++++++++++++---
 1 file changed, 115 insertions(+), 8 deletions(-)

--- a/drivers/infiniband/core/roce_gid_mgmt.c
+++ b/drivers/infiniband/core/roce_gid_mgmt.c
@@ -37,11 +37,20 @@
 
 /* For in6_dev_get/in6_dev_put */
 #include <net/addrconf.h>
+#ifdef MLX_USE_LAG_COMPAT
+#define MLX_IMPL_LAG_EVENTS
+#endif
 #include <net/bonding.h>
 
 #include <rdma/ib_cache.h>
 #include <rdma/ib_addr.h>
 
+#if defined(MLX_USE_LAG_COMPAT) || \
+	(defined(HAVE_NETDEV_NOTIFIER_CHANGEUPPER_INFO) && \
+	(defined(HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU) || defined(HAVE_NETDEV_FOR_EACH_ALL_UPPER_DEV_RCU)))
+#define USE_UPPER_INFO
+#endif
+
 static struct workqueue_struct *gid_cache_wq;
 
 bool roce_v1_noncompat_gid = true;
@@ -135,12 +144,17 @@ static enum bonding_slave_state is_eth_a
 								   struct net_device *upper)
 {
 	if (upper && netif_is_bond_master(upper)) {
+#ifdef HAVE_BONDING_H
 		struct net_device *pdev =
 			bond_option_active_slave_get_rcu(netdev_priv(upper));
 
 		if (pdev)
 			return dev == pdev ? BONDING_SLAVE_STATE_ACTIVE :
 				BONDING_SLAVE_STATE_INACTIVE;
+#else
+	return memcmp(upper->dev_addr, dev->dev_addr, ETH_ALEN) ?
+		BONDING_SLAVE_STATE_INACTIVE : BONDING_SLAVE_STATE_ACTIVE;
+#endif
 	}
 
 	return BONDING_SLAVE_STATE_NA;
@@ -375,6 +389,7 @@ static void enum_netdev_ipv4_ips(struct
 	}
 }
 
+#if IS_ENABLED(CONFIG_IPV6)
 static void enum_netdev_ipv6_ips(struct ib_device *ib_dev,
 				 u8 port, struct net_device *ndev)
 {
@@ -397,7 +412,11 @@ static void enum_netdev_ipv6_ips(struct
 		return;
 
 	read_lock_bh(&in6_dev->lock);
+#ifdef HAVE_INET6_IF_LIST
 	list_for_each_entry(ifp, &in6_dev->addr_list, if_list) {
+#else
+	for (ifp=in6_dev->addr_list; ifp; ifp=ifp->if_next) {
+#endif
 		struct sin6_list *entry = kzalloc(sizeof(*entry), GFP_ATOMIC);
 
 		if (!entry)
@@ -420,13 +439,15 @@ static void enum_netdev_ipv6_ips(struct
 		kfree(sin6_iter);
 	}
 }
+#endif
 
 static void _add_netdev_ips(struct ib_device *ib_dev, u8 port,
 			    struct net_device *ndev)
 {
 	enum_netdev_ipv4_ips(ib_dev, port, ndev);
-	if (IS_ENABLED(CONFIG_IPV6))
-		enum_netdev_ipv6_ips(ib_dev, port, ndev);
+#if IS_ENABLED(CONFIG_IPV6)
+	enum_netdev_ipv6_ips(ib_dev, port, ndev);
+#endif
 }
 
 static void add_netdev_ips(struct ib_device *ib_dev, u8 port,
@@ -485,7 +506,9 @@ static void enum_all_gids_of_dev_cb(stru
 	 * our feet
 	 */
 	rtnl_lock();
+#ifdef HAVE_RTNETLINK_NET_RWSEM
 	down_read(&net_rwsem);
+#endif
 	for_each_net(net)
 		for_each_netdev(net, ndev) {
 			/*
@@ -501,7 +524,9 @@ static void enum_all_gids_of_dev_cb(stru
 							 rdma_ndev, ndev))
 				_add_netdev_ips(ib_dev, port, ndev);
 		}
+#ifdef HAVE_RTNETLINK_NET_RWSEM
 	up_read(&net_rwsem);
+#endif
 	rtnl_unlock();
 }
 
@@ -530,6 +555,9 @@ static void callback_for_addr_gid_device
 			  &parsed->gid_attr);
 }
 
+#ifdef USE_UPPER_INFO
+
+#ifdef HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU
 struct upper_list {
 	struct list_head list;
 	struct net_device *upper;
@@ -549,6 +577,7 @@ static int netdev_upper_walk(struct net_
 
 	return 0;
 }
+#endif /* HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU */
 
 static void handle_netdev_upper(struct ib_device *ib_dev, u8 port,
 				void *cookie,
@@ -557,13 +586,52 @@ static void handle_netdev_upper(struct i
 						      struct net_device *ndev))
 {
 	struct net_device *ndev = cookie;
+#ifndef HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU
+	struct upper_list {
+		struct list_head list;
+		struct net_device *upper;
+	};
+	struct net_device *upper;
+#ifndef MLX_USE_LAG_COMPAT
+	struct list_head *iter;
+#endif
+#endif /* HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU */
 	struct upper_list *upper_iter;
 	struct upper_list *upper_temp;
 	LIST_HEAD(upper_list);
 
+#ifdef MLX_USE_LAG_COMPAT
+	rtnl_lock();
+#endif
 	rcu_read_lock();
+#ifndef HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU
+#ifndef MLX_USE_LAG_COMPAT
+	netdev_for_each_all_upper_dev_rcu(ndev, upper, iter) {
+		struct upper_list *entry;
+#else
+	for_each_netdev(dev_net(ndev), upper) {
+		struct upper_list *entry;
+
+		if (!rdma_is_upper_dev_rcu(ndev, upper))
+			continue;
+#endif
+		entry = kmalloc(sizeof(*entry), GFP_ATOMIC);
+		if (!entry) {
+			pr_info("roce_gid_mgmt: couldn't allocate entry to delete ndev\n");
+			continue;
+		}
+
+		list_add_tail(&entry->list, &upper_list);
+		dev_hold(upper);
+		entry->upper = upper;
+	}
+#else /* HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU */
 	netdev_walk_all_upper_dev_rcu(ndev, netdev_upper_walk, &upper_list);
+#endif /* HAVE_NETDEV_WALK_ALL_UPPER_DEV_RCU */
 	rcu_read_unlock();
+#ifdef MLX_USE_LAG_COMPAT
+	rtnl_unlock();
+#endif
 
 	handle_netdev(ib_dev, port, ndev);
 	list_for_each_entry_safe(upper_iter, upper_temp, &upper_list,
@@ -593,6 +661,8 @@ static void add_netdev_upper_ips(struct
 	handle_netdev_upper(ib_dev, port, cookie, _add_netdev_ips);
 }
 
+#endif /* USE_UPPER_INFO */
+
 static void del_netdev_default_ips_join(struct ib_device *ib_dev, u8 port,
 					struct net_device *rdma_ndev,
 					void *cookie)
@@ -666,16 +736,17 @@ static const struct netdev_event_work_cm
 	.filter	= is_eth_port_of_netdev_filter
 };
 
-static const struct netdev_event_work_cmd add_cmd_upper_ips = {
-	.cb	= add_netdev_upper_ips,
-	.filter = is_eth_port_of_netdev_filter
-};
-
 static const struct netdev_event_work_cmd bonding_default_add_cmd = {
 	.cb	= add_default_gids,
 	.filter	= is_upper_ndev_bond_master_filter
 };
 
+#ifdef USE_UPPER_INFO
+static const struct netdev_event_work_cmd add_cmd_upper_ips = {
+	.cb	= add_netdev_upper_ips,
+	.filter = is_eth_port_of_netdev_filter
+};
+
 static void
 ndev_event_unlink(struct netdev_notifier_changeupper_info *changeupper_info,
 		  struct netdev_event_work_cmd *cmds)
@@ -729,6 +800,7 @@ static void netdevice_event_changeupper(
 	else
 		ndev_event_unlink(changeupper_info, cmds);
 }
+#endif
 
 static const struct netdev_event_work_cmd add_default_gid_cmd = {
 	.cb	= add_default_gids,
@@ -751,9 +823,22 @@ static int netdevice_event(struct notifi
 				.filter = is_eth_port_of_netdev_filter
 			};
 	static const struct netdev_event_work_cmd bonding_event_ips_del_cmd = {
+#ifdef USE_UPPER_INFO
 		.cb = del_netdev_upper_ips, .filter = upper_device_filter};
-	struct net_device *ndev = netdev_notifier_info_to_dev(ptr);
+#else
+		.cb = del_netdev_ips, .filter = upper_device_filter};
+#endif
 	struct netdev_event_work_cmd cmds[ROCE_NETDEV_CALLBACK_SZ] = { {NULL} };
+	struct net_device *ndev;
+
+#ifdef MLX_USE_LAG_COMPAT
+	if (event == NETDEV_CHANGEUPPER || event == NETDEV_CHANGELOWERSTATE)
+		ndev = netdev_notifier_info_to_dev_v2(ptr);
+	else
+		ndev = netdev_notifier_info_to_dev(ptr);
+#else
+	ndev = netdev_notifier_info_to_dev(ptr);
+#endif
 
 	if (ndev->type != ARPHRD_ETHER)
 		return NOTIFY_DONE;
@@ -761,6 +846,9 @@ static int netdevice_event(struct notifi
 	switch (event) {
 	case NETDEV_REGISTER:
 	case NETDEV_UP:
+#ifndef USE_UPPER_INFO
+	case NETDEV_JOIN:
+#endif
 		cmds[0] = bonding_default_del_cmd_join;
 		cmds[1] = add_default_gid_cmd;
 		cmds[2] = add_cmd;
@@ -781,18 +869,24 @@ static int netdevice_event(struct notifi
 		}
 		break;
 
+#ifdef USE_UPPER_INFO
 	case NETDEV_CHANGEUPPER:
 		netdevice_event_changeupper(ndev,
 			container_of(ptr, struct netdev_notifier_changeupper_info, info),
 			cmds);
 		break;
+#endif
 
 	case NETDEV_BONDING_FAILOVER:
 		cmds[0] = bonding_event_ips_del_cmd;
 		/* Add default GIDs of the bond device */
 		cmds[1] = bonding_default_add_cmd;
+#ifdef USE_UPPER_INFO
 		/* Add IP based GIDs of the bond device */
 		cmds[2] = add_cmd_upper_ips;
+#else
+		cmds[2] = add_cmd;
+#endif
 		break;
 
 	default:
@@ -895,6 +989,13 @@ static struct notifier_block nb_inet6add
 	.notifier_call = inet6addr_event
 };
 
+#ifdef MLX_USE_LAG_COMPAT
+static void roce_lag_compat_netdev_event(unsigned long event, void *ptr)
+{
+	nb_netdevice.notifier_call(&nb_netdevice, event, ptr);
+}
+#endif
+
 int __init roce_gid_mgmt_init(void)
 {
 	gid_cache_wq = alloc_ordered_workqueue("gid-cache-wq", 0);
@@ -911,11 +1012,17 @@ int __init roce_gid_mgmt_init(void)
 	 */
 	register_netdevice_notifier(&nb_netdevice);
 
+#ifdef MLX_USE_LAG_COMPAT
+	mlx_lag_compat_events_open(roce_lag_compat_netdev_event);
+#endif
 	return 0;
 }
 
 void __exit roce_gid_mgmt_cleanup(void)
 {
+#ifdef MLX_USE_LAG_COMPAT
+	mlx_lag_compat_events_close();
+#endif
 	if (IS_ENABLED(CONFIG_IPV6))
 		unregister_inet6addr_notifier(&nb_inet6addr);
 	unregister_inetaddr_notifier(&nb_inetaddr);
