From: Mikhael Goikhman <migo@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en_stats.c

Change-Id: Ic675fff0dbbd262b9d67bf416d869e076d8a5e50
---
 drivers/net/ethernet/mellanox/mlx5/core/en_stats.c | 99 +++++++++++++++++++---
 1 file changed, 89 insertions(+), 10 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_stats.c
@@ -48,7 +48,7 @@ static const struct counter_desc sw_stat
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_added_vlan_packets) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_nop) },
 
-#ifdef CONFIG_MLX5_EN_TLS
+#if defined(CONFIG_MLX5_EN_TLS) && defined(HAVE_UAPI_LINUX_TLS_H)
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_tls_ooo) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_tls_resync_bytes) },
 #endif
@@ -63,12 +63,16 @@ static const struct counter_desc sw_stat
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_csum_complete_tail) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_csum_complete_tail_slow) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_csum_unnecessary_inner) },
+#ifdef HAVE_XDP_BUFF
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_xdp_drop) },
+#ifdef HAVE_XDP_REDIRECT
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_xdp_redirect) },
+#endif
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_xdp_tx_xmit) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_xdp_tx_full) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_xdp_tx_err) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_xdp_tx_cqe) },
+#endif
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_csum_none) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_csum_partial) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_csum_partial_inner) },
@@ -79,10 +83,17 @@ static const struct counter_desc sw_stat
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_cqes) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_queue_wake) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_cqe_err) },
+#ifdef CONFIG_COMPAT_LRO_ENABLED_IPOIB
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_sw_lro_aggregated) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_sw_lro_flushed) },
+	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_sw_lro_no_desc) },
+#endif
+#ifdef HAVE_XDP_REDIRECT
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_xdp_xmit) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_xdp_full) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_xdp_err) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, tx_xdp_cqes) },
+#endif
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_wqe_err) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_mpwqe_filler_cqes) },
 	{ MLX5E_DECLARE_STAT(struct mlx5e_sw_stats, rx_mpwqe_filler_strides) },
@@ -131,6 +142,26 @@ static int mlx5e_grp_sw_fill_stats(struc
 	return idx;
 }
 
+#ifdef CONFIG_COMPAT_LRO_ENABLED_IPOIB
+static void mlx5e_update_sw_lro_stats(struct mlx5e_priv *priv)
+{
+	int i;
+	struct mlx5e_sw_stats *s = &priv->stats.sw;
+
+	s->rx_sw_lro_aggregated = 0;
+	s->rx_sw_lro_flushed = 0;
+	s->rx_sw_lro_no_desc = 0;
+
+	for (i = 0; i < priv->channels.num; i++) {
+		struct mlx5e_sw_lro *sw_lro = &priv->sw_lro[i];
+
+		s->rx_sw_lro_aggregated += sw_lro->lro_mgr.stats.aggregated;
+		s->rx_sw_lro_flushed += sw_lro->lro_mgr.stats.flushed;
+		s->rx_sw_lro_no_desc += sw_lro->lro_mgr.stats.no_desc;
+	}
+}
+#endif
+
 void mlx5e_grp_sw_update_stats(struct mlx5e_priv *priv)
 {
 	struct mlx5e_sw_stats temp, *s = &temp;
@@ -141,8 +172,12 @@ void mlx5e_grp_sw_update_stats(struct ml
 	for (i = 0; i < mlx5e_get_netdev_max_channels(priv); i++) {
 		struct mlx5e_channel_stats *channel_stats =
 			&priv->channel_stats[i];
+#ifdef HAVE_XDP_REDIRECT
 		struct mlx5e_xdpsq_stats *xdpsq_red_stats = &channel_stats->xdpsq;
+#endif
+#ifdef HAVE_XDP_BUFF
 		struct mlx5e_xdpsq_stats *xdpsq_stats = &channel_stats->rq_xdpsq;
+#endif
 		struct mlx5e_rq_stats *rq_stats = &channel_stats->rq;
 		struct mlx5e_ch_stats *ch_stats = &channel_stats->ch;
 		int j;
@@ -159,12 +194,16 @@ void mlx5e_grp_sw_update_stats(struct ml
 		s->rx_csum_complete_tail_slow += rq_stats->csum_complete_tail_slow;
 		s->rx_csum_unnecessary += rq_stats->csum_unnecessary;
 		s->rx_csum_unnecessary_inner += rq_stats->csum_unnecessary_inner;
+#ifdef HAVE_XDP_BUFF
 		s->rx_xdp_drop     += rq_stats->xdp_drop;
+#ifdef HAVE_XDP_REDIRECT
 		s->rx_xdp_redirect += rq_stats->xdp_redirect;
+#endif
 		s->rx_xdp_tx_xmit  += xdpsq_stats->xmit;
 		s->rx_xdp_tx_full  += xdpsq_stats->full;
 		s->rx_xdp_tx_err   += xdpsq_stats->err;
 		s->rx_xdp_tx_cqe   += xdpsq_stats->cqes;
+#endif
 		s->rx_wqe_err   += rq_stats->wqe_err;
 		s->rx_mpwqe_filler_cqes    += rq_stats->mpwqe_filler_cqes;
 		s->rx_mpwqe_filler_strides += rq_stats->mpwqe_filler_strides;
@@ -186,11 +225,13 @@ void mlx5e_grp_sw_update_stats(struct ml
 		s->ch_arm         += ch_stats->arm;
 		s->ch_aff_change  += ch_stats->aff_change;
 		s->ch_eq_rearm    += ch_stats->eq_rearm;
+#ifdef HAVE_XDP_REDIRECT
 		/* xdp redirect */
 		s->tx_xdp_xmit    += xdpsq_red_stats->xmit;
 		s->tx_xdp_full    += xdpsq_red_stats->full;
 		s->tx_xdp_err     += xdpsq_red_stats->err;
 		s->tx_xdp_cqes    += xdpsq_red_stats->cqes;
+#endif
 
 		for (j = 0; j < priv->max_opened_tc; j++) {
 			struct mlx5e_sq_stats *sq_stats = &channel_stats->sq[j];
@@ -212,7 +253,7 @@ void mlx5e_grp_sw_update_stats(struct ml
 			s->tx_csum_partial_inner += sq_stats->csum_partial_inner;
 			s->tx_csum_none		+= sq_stats->csum_none;
 			s->tx_csum_partial	+= sq_stats->csum_partial;
-#ifdef CONFIG_MLX5_EN_TLS
+#if defined(CONFIG_MLX5_EN_TLS) && defined(HAVE_UAPI_LINUX_TLS_H)
 			s->tx_tls_ooo		+= sq_stats->tls_ooo;
 			s->tx_tls_resync_bytes	+= sq_stats->tls_resync_bytes;
 #endif
@@ -221,6 +262,10 @@ void mlx5e_grp_sw_update_stats(struct ml
 	}
 
 	memcpy(&priv->stats.sw, s, sizeof(*s));
+
+#ifdef CONFIG_COMPAT_LRO_ENABLED_IPOIB
+	mlx5e_update_sw_lro_stats(priv);
+#endif
 }
 
 static const struct counter_desc q_stats_desc[] = {
@@ -397,7 +442,11 @@ static void mlx5e_vf_rep_update_hw_count
 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
 	struct mlx5_eswitch_rep *rep = rpriv->rep;
+#ifdef HAVE_RTNL_LINK_STATS64
 	struct rtnl_link_stats64 *vport_stats;
+#else
+	struct rtnl_link_stats *vport_stats;
+#endif
 	struct ifla_vf_stats vf_stats;
 	int err;
 
@@ -418,7 +467,11 @@ static void mlx5e_vf_rep_update_hw_count
 static void mlx5e_uplink_rep_update_hw_counters(struct mlx5e_priv *priv)
 {
 	struct mlx5e_pport_stats *pstats = &priv->stats.pport;
+#ifdef HAVE_RTNL_LINK_STATS64
 	struct rtnl_link_stats64 *vport_stats;
+#else
+	struct rtnl_link_stats *vport_stats;
+#endif
 
 	mlx5e_grp_802_3_update_stats(priv);
 
@@ -1280,8 +1333,12 @@ static const struct counter_desc rq_stat
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, csum_unnecessary) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, csum_unnecessary_inner) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, csum_none) },
+#ifdef HAVE_XDP_BUFF
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, xdp_drop) },
+#ifdef HAVE_XDP_REDIRECT
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, xdp_redirect) },
+#endif
+#endif
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, lro_packets) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, lro_bytes) },
 	{ MLX5E_DECLARE_RX_STAT(struct mlx5e_rq_stats, ecn_mark) },
@@ -1323,21 +1380,25 @@ static const struct counter_desc sq_stat
 	{ MLX5E_DECLARE_TX_STAT(struct mlx5e_sq_stats, cqes) },
 	{ MLX5E_DECLARE_TX_STAT(struct mlx5e_sq_stats, wake) },
 	{ MLX5E_DECLARE_TX_STAT(struct mlx5e_sq_stats, cqe_err) },
-};
-
+}
+;
+#ifdef HAVE_XDP_BUFF
 static const struct counter_desc rq_xdpsq_stats_desc[] = {
 	{ MLX5E_DECLARE_RQ_XDPSQ_STAT(struct mlx5e_xdpsq_stats, xmit) },
 	{ MLX5E_DECLARE_RQ_XDPSQ_STAT(struct mlx5e_xdpsq_stats, full) },
 	{ MLX5E_DECLARE_RQ_XDPSQ_STAT(struct mlx5e_xdpsq_stats, err) },
 	{ MLX5E_DECLARE_RQ_XDPSQ_STAT(struct mlx5e_xdpsq_stats, cqes) },
 };
+#endif
 
+#ifdef HAVE_XDP_REDIRECT
 static const struct counter_desc xdpsq_stats_desc[] = {
 	{ MLX5E_DECLARE_XDPSQ_STAT(struct mlx5e_xdpsq_stats, xmit) },
 	{ MLX5E_DECLARE_XDPSQ_STAT(struct mlx5e_xdpsq_stats, full) },
 	{ MLX5E_DECLARE_XDPSQ_STAT(struct mlx5e_xdpsq_stats, err) },
 	{ MLX5E_DECLARE_XDPSQ_STAT(struct mlx5e_xdpsq_stats, cqes) },
 };
+#endif
 
 static const struct counter_desc ch_stats_desc[] = {
 	{ MLX5E_DECLARE_CH_STAT(struct mlx5e_ch_stats, events) },
@@ -1349,8 +1410,12 @@ static const struct counter_desc ch_stat
 
 #define NUM_RQ_STATS			ARRAY_SIZE(rq_stats_desc)
 #define NUM_SQ_STATS			ARRAY_SIZE(sq_stats_desc)
-#define NUM_XDPSQ_STATS			ARRAY_SIZE(xdpsq_stats_desc)
-#define NUM_RQ_XDPSQ_STATS		ARRAY_SIZE(rq_xdpsq_stats_desc)
+#ifdef HAVE_XDP_REDIRECT
+#define NUM_XDPSQ_STATS                 ARRAY_SIZE(xdpsq_stats_desc)
+#endif
+#ifdef HAVE_XDP_BUFF
+#define NUM_RQ_XDPSQ_STATS              ARRAY_SIZE(rq_xdpsq_stats_desc)
+#endif
 #define NUM_CH_STATS			ARRAY_SIZE(ch_stats_desc)
 #define MLX5E_GET_PFLAG_PER_CH_STATS(priv) \
 	(MLX5E_GET_PFLAG(&(priv)->channels.params, MLX5E_PFLAG_PER_CH_STATS))
@@ -1364,8 +1429,16 @@ static int mlx5e_grp_channels_get_num_st
 
 	return (NUM_RQ_STATS * max_nch) +
 	       (NUM_CH_STATS * max_nch) +
-	       (NUM_RQ_XDPSQ_STATS * max_nch) +
-	       (NUM_XDPSQ_STATS * max_nch) +
+#ifdef HAVE_XDP_BUFF
+		(NUM_RQ_XDPSQ_STATS * max_nch) +
+#ifdef HAVE_XDP_REDIRECT
+		(NUM_XDPSQ_STATS * max_nch) +
+#else
+		0 +
+#endif
+#else
+		0 +
+#endif
 #ifndef CONFIG_MLX5_EN_SPECIAL_SQ
 	       (NUM_SQ_STATS * max_nch * priv->max_opened_tc);
 #else
@@ -1392,9 +1465,11 @@ static int mlx5e_grp_channels_fill_strin
 		for (j = 0; j < NUM_RQ_STATS; j++)
 			sprintf(data + (idx++) * ETH_GSTRING_LEN,
 				rq_stats_desc[j].format, i);
+#ifdef HAVE_XDP_BUFF
 		for (j = 0; j < NUM_RQ_XDPSQ_STATS; j++)
 			sprintf(data + (idx++) * ETH_GSTRING_LEN,
 				rq_xdpsq_stats_desc[j].format, i);
+#endif
 	}
 
 	for (tc = 0; tc < priv->max_opened_tc; tc++)
@@ -1403,11 +1478,12 @@ static int mlx5e_grp_channels_fill_strin
 				sprintf(data + (idx++) * ETH_GSTRING_LEN,
 					sq_stats_desc[j].format,
 					priv->channel_tc2txq[i][tc]);
-
+#ifdef HAVE_XDP_REDIRECT
 	for (i = 0; i < max_nch; i++)
 		for (j = 0; j < NUM_XDPSQ_STATS; j++)
 			sprintf(data + (idx++) * ETH_GSTRING_LEN,
 				xdpsq_stats_desc[j].format, i);
+#endif
 
 #ifdef CONFIG_MLX5_EN_SPECIAL_SQ
 	/* Special TX queue counters */
@@ -1442,10 +1518,12 @@ static int mlx5e_grp_channels_fill_stats
 			data[idx++] =
 				MLX5E_READ_CTR64_CPU(&priv->channel_stats[i].rq,
 						     rq_stats_desc, j);
+#ifdef HAVE_XDP_BUFF
 		for (j = 0; j < NUM_RQ_XDPSQ_STATS; j++)
 			data[idx++] =
 				MLX5E_READ_CTR64_CPU(&priv->channel_stats[i].rq_xdpsq,
 						     rq_xdpsq_stats_desc, j);
+#endif
 	}
 
 	for (tc = 0; tc < priv->max_opened_tc; tc++)
@@ -1454,12 +1532,13 @@ static int mlx5e_grp_channels_fill_stats
 				data[idx++] =
 					MLX5E_READ_CTR64_CPU(&priv->channel_stats[i].sq[tc],
 							     sq_stats_desc, j);
-
+#ifdef HAVE_XDP_REDIRECT
 	for (i = 0; i < max_nch; i++)
 		for (j = 0; j < NUM_XDPSQ_STATS; j++)
 			data[idx++] =
 				MLX5E_READ_CTR64_CPU(&priv->channel_stats[i].xdpsq,
 						     xdpsq_stats_desc, j);
+#endif
 
 #ifdef CONFIG_MLX5_EN_SPECIAL_SQ
 	/* Special TX queue counters */
