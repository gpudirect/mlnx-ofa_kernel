From: Alaa Hleihel <alaa@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en_tc.c

Change-Id: I409d0c273d880163a0df891152c9dd8cf93e1c8e
---
 drivers/net/ethernet/mellanox/mlx5/core/en_tc.c | 397 +++++++++++++++++++++++-
 1 file changed, 385 insertions(+), 12 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_tc.c
@@ -30,22 +30,46 @@
  * SOFTWARE.
  */
 
-#include <net/flow_dissector.h>
 #include <net/sch_generic.h>
 #include <net/pkt_cls.h>
+#ifdef HAVE_TC_GACT_H
 #include <net/tc_act/tc_gact.h>
+#endif
+#ifdef HAVE_IS_TCF_SKBEDIT_MARK
 #include <net/tc_act/tc_skbedit.h>
+#endif
 #include <linux/mlx5/fs.h>
 #include <linux/mlx5/device.h>
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 #include <linux/rhashtable.h>
+#endif
+#ifdef CONFIG_NET_SWITCHDEV
 #include <net/switchdev.h>
+#endif
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 #include <net/tc_act/tc_mirred.h>
+#endif
+#ifdef HAVE_IS_TCF_VLAN
 #include <net/tc_act/tc_vlan.h>
+#endif
+#ifdef HAVE_TCF_TUNNEL_INFO
 #include <net/tc_act/tc_tunnel_key.h>
+#endif
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
+#include <linux/tc_act/tc_pedit.h>
 #include <net/tc_act/tc_pedit.h>
+#endif
+#ifdef HAVE_TCA_CSUM_UPDATE_FLAG_IPV4HDR
 #include <net/tc_act/tc_csum.h>
+#endif
+#ifdef HAVE_TCF_TUNNEL_INFO
 #include <net/vxlan.h>
+#endif
 #include <net/arp.h>
+#ifdef HAVE_TC_FLOWER_OFFLOAD
+#include <net/flow_dissector.h>
+#endif
+
 #include "en.h"
 #include "en_rep.h"
 #include "en_tc.h"
@@ -54,10 +78,66 @@
 #include "fs_core.h"
 #include "en/port.h"
 
+#if defined(HAVE_TC_FLOWER_OFFLOAD) && \
+    (!defined(HAVE_SWITCHDEV_PORT_SAME_PARENT_ID) || \
+    !defined(CONFIG_NET_SWITCHDEV))
+#include <net/bonding.h>
+static bool switchdev_port_same_parent_id(struct net_device *a,
+					  struct net_device *b)
+{
+	struct mlx5e_priv *priv_a, *priv_b;
+	struct net_device *ndev;
+	struct bonding *bond;
+	bool ret = true;
+
+	if (netif_is_bond_master(b)) {
+		bond = netdev_priv(b);
+		if (!bond_has_slaves(bond))
+			return false;
+
+		rcu_read_lock();
+#ifdef for_each_netdev_in_bond_rcu
+		for_each_netdev_in_bond_rcu(b, ndev) {
+#else
+		for_each_netdev_in_bond(b, ndev) {
+#endif
+			ret &= switchdev_port_same_parent_id(a, ndev);
+			if (!ret)
+				break;
+		}
+		rcu_read_unlock();
+		return ret;
+	}
+
+	if (!(a->features & NETIF_F_HW_TC) || !(b->features & NETIF_F_HW_TC))
+		return false;
+
+	priv_a = netdev_priv(a);
+	priv_b = netdev_priv(b);
+
+	if (!priv_a->mdev->priv.eswitch || !priv_b->mdev->priv.eswitch)
+		return false;
+
+	if (priv_a->mdev->priv.eswitch->mode != SRIOV_OFFLOADS ||
+	    priv_b->mdev->priv.eswitch->mode != SRIOV_OFFLOADS)
+		return false;
+
+	if (priv_a->mdev == priv_b->mdev)
+		return true;
+
+	if (mlx5_lag_is_active(priv_a->mdev))
+		return mlx5_lag_get_peer_mdev(priv_a->mdev) == priv_b->mdev;
+
+	return false;
+}
+#endif
+
 struct mlx5_nic_flow_attr {
 	u32 action;
 	u32 flow_tag;
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	u32 mod_hdr_id;
+#endif
 	u32 hairpin_tirn;
 	u8 match_level;
 	struct mlx5_flow_table	*hairpin_ft;
@@ -79,6 +159,7 @@ enum {
 
 #define MLX5E_TC_MAX_SPLITS 1
 
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 struct mlx5e_tc_flow {
 	struct rhash_head	node;
 	struct mlx5e_priv	*priv;
@@ -86,8 +167,12 @@ struct mlx5e_tc_flow {
 	u8			flags;
 	struct mlx5_flow_handle *rule[MLX5E_TC_MAX_SPLITS + 1];
 	struct mlx5e_tc_flow    *peer_flow;
+#ifdef HAVE_TCF_TUNNEL_INFO
 	struct list_head	encap;   /* flows sharing the same encap ID */
+#endif
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	struct list_head	mod_hdr; /* flows sharing the same mod hdr ID */
+#endif
 	struct list_head	hairpin; /* flows sharing the same hairpin */
 	union {
 		struct mlx5_esw_flow_attr esw_attr[0];
@@ -96,10 +181,14 @@ struct mlx5e_tc_flow {
 };
 
 struct mlx5e_tc_flow_parse_attr {
+#ifdef HAVE_TCF_TUNNEL_INFO
 	struct ip_tunnel_info tun_info;
+#endif
 	struct mlx5_flow_spec spec;
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	int num_mod_hdr_actions;
 	void *mod_hdr_actions;
+#endif
 	int mirred_ifindex;
 };
 
@@ -132,6 +221,7 @@ struct mlx5e_hairpin_entry {
 	struct mlx5e_hairpin *hp;
 };
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 struct mod_hdr_key {
 	int num_actions;
 	void *actions;
@@ -260,6 +350,7 @@ static void mlx5e_detach_mod_hdr(struct
 		kfree(mh);
 	}
 }
+#endif /* HAVE_TCF_PEDIT_TCFP_KEYS_EX */
 
 static
 struct mlx5_core_dev *mlx5e_hairpin_get_mdev(struct net *net, int ifindex)
@@ -733,6 +824,7 @@ mlx5e_tc_add_nic_flow(struct mlx5e_priv
 		attr->counter = counter;
 	}
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR) {
 		err = mlx5e_attach_mod_hdr(priv, flow, parse_attr);
 		flow_act.modify_id = attr->mod_hdr_id;
@@ -740,6 +832,7 @@ mlx5e_tc_add_nic_flow(struct mlx5e_priv
 		if (err)
 			goto err_create_mod_hdr_id;
 	}
+#endif
 
 	if (IS_ERR_OR_NULL(priv->fs.tc.t)) {
 		int tc_grp_size, tc_tbl_size;
@@ -788,9 +881,11 @@ err_add_rule:
 		priv->fs.tc.t = NULL;
 	}
 err_create_ft:
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
 		mlx5e_detach_mod_hdr(priv, flow);
 err_create_mod_hdr_id:
+#endif
 	mlx5_fc_destroy(dev, counter);
 err_fc_create:
 	if (flow->flags & MLX5E_TC_FLOW_HAIRPIN)
@@ -814,13 +909,16 @@ static void mlx5e_tc_del_nic_flow(struct
 		priv->fs.tc.t = NULL;
 	}
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
 		mlx5e_detach_mod_hdr(priv, flow);
+#endif
 
 	if (flow->flags & MLX5E_TC_FLOW_HAIRPIN)
 		mlx5e_hairpin_flow_del(priv, flow);
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 static void mlx5e_detach_encap(struct mlx5e_priv *priv,
 			       struct mlx5e_tc_flow *flow);
 
@@ -829,6 +927,7 @@ static int mlx5e_attach_encap(struct mlx
 			      struct net_device *mirred_dev,
 			      struct net_device **encap_dev,
 			      struct mlx5e_tc_flow *flow);
+#endif
 
 static int
 mlx5e_tc_add_fdb_flow(struct mlx5e_priv *priv,
@@ -837,12 +936,19 @@ mlx5e_tc_add_fdb_flow(struct mlx5e_priv
 {
 	struct mlx5_eswitch *esw = priv->mdev->priv.eswitch;
 	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
+#ifdef HAVE_TCF_TUNNEL_INFO
 	struct net_device *out_dev, *encap_dev = NULL;
+#endif
 	struct mlx5_fc *counter = NULL;
+#ifdef HAVE_TCF_TUNNEL_INFO
 	struct mlx5e_rep_priv *rpriv;
 	struct mlx5e_priv *out_priv;
 	int err = 0, encap_err = 0;
+#else
+	int err;
+#endif
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT) {
 		out_dev = __dev_get_by_index(dev_net(priv->netdev),
 					     attr->parse_attr->mirred_ifindex);
@@ -857,20 +963,23 @@ mlx5e_tc_add_fdb_flow(struct mlx5e_priv
 		attr->out_rep[attr->out_count] = rpriv->rep;
 		attr->out_mdev[attr->out_count++] = out_priv->mdev;
 	}
+#endif
 
 	err = mlx5_eswitch_add_vlan_action(esw, attr);
 	if (err)
 		goto err_add_vlan;
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR) {
 		err = mlx5e_attach_mod_hdr(priv, flow, parse_attr);
 		kfree(parse_attr->mod_hdr_actions);
 		if (err)
 			goto err_mod_hdr;
 	}
+#endif
 
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_COUNT) {
-		counter = mlx5_fc_create(esw->dev, true);
+		counter = mlx5_fc_create(attr->counter_dev, true);
 		if (IS_ERR(counter)) {
 			err = PTR_ERR(counter);
 			goto err_create_counter;
@@ -879,6 +988,7 @@ mlx5e_tc_add_fdb_flow(struct mlx5e_priv
 		attr->counter = counter;
 	}
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 	/* we get here if (1) there's no error or when
 	 * (2) there's an encap action and we're on -EAGAIN (no valid neigh)
 	 */
@@ -903,16 +1013,21 @@ mlx5e_tc_add_fdb_flow(struct mlx5e_priv
 err_fwd_rule:
 	mlx5_eswitch_del_offloaded_rule(esw, flow->rule[0], attr);
 err_add_rule:
-	mlx5_fc_destroy(esw->dev, counter);
+	mlx5_fc_destroy(attr->counter_dev, counter);
+#endif
 err_create_counter:
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
 		mlx5e_detach_mod_hdr(priv, flow);
 err_mod_hdr:
+#endif
 	mlx5_eswitch_del_vlan_action(esw, attr);
 err_add_vlan:
+#ifdef HAVE_TCF_TUNNEL_INFO
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT)
 		mlx5e_detach_encap(priv, flow);
 err_attach_encap:
+#endif
 	return err;
 }
 
@@ -923,7 +1038,9 @@ static void mlx5e_tc_del_fdb_flow(struct
 	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
 
 	if (flow->flags & MLX5E_TC_FLOW_OFFLOADED) {
+#ifdef HAVE_TCF_TUNNEL_INFO
 		flow->flags &= ~MLX5E_TC_FLOW_OFFLOADED;
+#endif
 		if (attr->mirror_count)
 			mlx5_eswitch_del_offloaded_rule(esw, flow->rule[1], attr);
 		mlx5_eswitch_del_offloaded_rule(esw, flow->rule[0], attr);
@@ -931,16 +1048,19 @@ static void mlx5e_tc_del_fdb_flow(struct
 
 	mlx5_eswitch_del_vlan_action(esw, attr);
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT) {
 		mlx5e_detach_encap(priv, flow);
 		kvfree(attr->parse_attr);
 	}
-
+#endif
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
 		mlx5e_detach_mod_hdr(priv, flow);
+#endif
 
 	if (attr->action & MLX5_FLOW_CONTEXT_ACTION_COUNT)
-		mlx5_fc_destroy(esw->dev, attr->counter);
+		mlx5_fc_destroy(attr->counter_dev, attr->counter);
 }
 
 static struct mlx5_fc *mlx5e_tc_get_counter(struct mlx5e_tc_flow *flow)
@@ -951,6 +1071,7 @@ static struct mlx5_fc *mlx5e_tc_get_coun
 		return flow->nic_attr->counter;
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 void mlx5e_tc_encap_flows_add(struct mlx5e_priv *priv,
 			      struct mlx5e_encap_entry *e)
 {
@@ -1033,9 +1154,12 @@ void mlx5e_tc_update_neigh_used_value(st
 
 	if (m_neigh->family == AF_INET)
 		tbl = &arp_tbl;
-#if IS_ENABLED(CONFIG_IPV6)
-	else if (m_neigh->family == AF_INET6)
-		tbl = &nd_tbl;
+#if defined(__IPV6_SUPPORT__) && IS_ENABLED(CONFIG_IPV6)
+	else if (m_neigh->family == AF_INET6) {
+		if (!ipv6_stub)
+			return;
+		tbl = ipv6_stub->nd_tbl;
+	}
 #endif
 	else
 		return;
@@ -1092,6 +1216,7 @@ static void mlx5e_detach_encap(struct ml
 		kfree(e);
 	}
 }
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
 static void mlx5e_tc_del_flow(struct mlx5e_priv *priv,
 			      struct mlx5e_tc_flow *flow)
@@ -1108,6 +1233,7 @@ static void mlx5e_tc_del_flow(struct mlx
 	}
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 static void parse_vxlan_attr(struct mlx5_flow_spec *spec,
 			     struct tc_cls_flower_offload *f)
 {
@@ -1263,6 +1389,7 @@ vxlan_match_offload_err:
 
 	return 0;
 }
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
 static int __parse_cls_flower(struct mlx5e_priv *priv,
 			      struct mlx5_flow_spec *spec,
@@ -1282,22 +1409,37 @@ static int __parse_cls_flower(struct mlx
 	    ~(BIT(FLOW_DISSECTOR_KEY_CONTROL) |
 	      BIT(FLOW_DISSECTOR_KEY_BASIC) |
 	      BIT(FLOW_DISSECTOR_KEY_ETH_ADDRS) |
+#ifdef HAVE_FLOW_DISSECTOR_KEY_VLAN
 	      BIT(FLOW_DISSECTOR_KEY_VLAN) |
+#else
+	      BIT(FLOW_DISSECTOR_KEY_VLANID) |
+#endif
 	      BIT(FLOW_DISSECTOR_KEY_IPV4_ADDRS) |
 	      BIT(FLOW_DISSECTOR_KEY_IPV6_ADDRS) |
+#ifdef HAVE_TCF_TUNNEL_INFO
 	      BIT(FLOW_DISSECTOR_KEY_PORTS) |
 	      BIT(FLOW_DISSECTOR_KEY_ENC_KEYID) |
 	      BIT(FLOW_DISSECTOR_KEY_ENC_IPV4_ADDRS) |
 	      BIT(FLOW_DISSECTOR_KEY_ENC_IPV6_ADDRS) |
 	      BIT(FLOW_DISSECTOR_KEY_ENC_PORTS)	|
 	      BIT(FLOW_DISSECTOR_KEY_ENC_CONTROL) |
+#else
+	      BIT(FLOW_DISSECTOR_KEY_PORTS) |
+#endif
+#ifdef HAVE_FLOW_DISSECTOR_KEY_TCP
 	      BIT(FLOW_DISSECTOR_KEY_TCP) |
+#endif
+#ifdef HAVE_FLOW_DISSECTOR_KEY_IP
 	      BIT(FLOW_DISSECTOR_KEY_IP))) {
+#else
+	      0)) {
+#endif
 		netdev_warn(priv->netdev, "Unsupported key used: 0x%x\n",
 			    f->dissector->used_keys);
 		return -EOPNOTSUPP;
 	}
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 	if ((dissector_uses_key(f->dissector,
 				FLOW_DISSECTOR_KEY_ENC_IPV4_ADDRS) ||
 	     dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_ENC_KEYID) ||
@@ -1325,6 +1467,7 @@ static int __parse_cls_flower(struct mlx
 		headers_v = MLX5_ADDR_OF(fte_match_param, spec->match_value,
 					 inner_headers);
 	}
+#endif
 
 	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_BASIC)) {
 		struct flow_dissector_key_basic *key =
@@ -1344,6 +1487,7 @@ static int __parse_cls_flower(struct mlx
 			*match_level = MLX5_MATCH_L2;
 	}
 
+#ifdef HAVE_FLOW_DISSECTOR_KEY_VLAN
 	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_VLAN)) {
 		struct flow_dissector_key_vlan *key =
 			skb_flow_dissector_target(f->dissector,
@@ -1365,6 +1509,25 @@ static int __parse_cls_flower(struct mlx
 
 			*match_level = MLX5_MATCH_L2;
 		}
+#else
+	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_VLANID)) {
+		struct flow_dissector_key_tags *key =
+			skb_flow_dissector_target(f->dissector,
+						  FLOW_DISSECTOR_KEY_VLANID,
+						  f->key);
+		struct flow_dissector_key_tags *mask =
+			skb_flow_dissector_target(f->dissector,
+						  FLOW_DISSECTOR_KEY_VLANID,
+						  f->mask);
+		if (mask->vlan_id) {
+			MLX5_SET(fte_match_set_lyr_2_4, headers_c, cvlan_tag, 1);
+			MLX5_SET(fte_match_set_lyr_2_4, headers_v, cvlan_tag, 1);
+			MLX5_SET(fte_match_set_lyr_2_4, headers_c, first_vid, mask->vlan_id);
+			MLX5_SET(fte_match_set_lyr_2_4, headers_v, first_vid, key->vlan_id);
+
+			*match_level = MLX5_MATCH_L2;
+		}
+#endif
 	} else if (*match_level != MLX5_MATCH_NONE) {
 		MLX5_SET(fte_match_set_lyr_2_4, headers_c, svlan_tag, 1);
 		MLX5_SET(fte_match_set_lyr_2_4, headers_c, cvlan_tag, 1);
@@ -1505,6 +1668,7 @@ static int __parse_cls_flower(struct mlx
 			*match_level = MLX5_MATCH_L3;
 	}
 
+#ifdef HAVE_FLOW_DISSECTOR_KEY_IP
 	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_IP)) {
 		struct flow_dissector_key_ip *key =
 			skb_flow_dissector_target(f->dissector,
@@ -1532,6 +1696,7 @@ static int __parse_cls_flower(struct mlx
 		if (mask->tos || mask->ttl)
 			*match_level = MLX5_MATCH_L3;
 	}
+#endif
 
 	/* ***  L3 attributes parsing up to here *** */
 
@@ -1578,6 +1743,7 @@ static int __parse_cls_flower(struct mlx
 			*match_level = MLX5_MATCH_L4;
 	}
 
+#ifdef HAVE_FLOW_DISSECTOR_KEY_TCP
 	if (dissector_uses_key(f->dissector, FLOW_DISSECTOR_KEY_TCP)) {
 		struct flow_dissector_key_tcp *key =
 			skb_flow_dissector_target(f->dissector,
@@ -1596,6 +1762,7 @@ static int __parse_cls_flower(struct mlx
 		if (mask->flags)
 			*match_level = MLX5_MATCH_L4;
 	}
+#endif
 
 	return 0;
 }
@@ -1634,6 +1801,7 @@ static int parse_cls_flower(struct mlx5e
 	return err;
 }
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 struct pedit_headers {
 	struct ethhdr  eth;
 	struct iphdr   ip4;
@@ -1917,6 +2085,7 @@ out_err:
 	return err;
 }
 
+#ifdef HAVE_TCA_CSUM_UPDATE_FLAG_IPV4HDR
 static bool csum_offload_supported(struct mlx5e_priv *priv, u32 action, u32 update_flags)
 {
 	u32 prot_flags = TCA_CSUM_UPDATE_FLAG_IPV4HDR | TCA_CSUM_UPDATE_FLAG_TCP |
@@ -1938,13 +2107,18 @@ static bool csum_offload_supported(struc
 
 	return true;
 }
+#endif
 
 static bool modify_header_match_supported(struct mlx5_flow_spec *spec,
 					  struct tcf_exts *exts)
 {
 	const struct tc_action *a;
 	bool modify_ip_header;
+#ifdef tcf_exts_for_each_action
+	int n;
+#else
 	LIST_HEAD(actions);
+#endif
 	u8 htype, ip_proto;
 	void *headers_v;
 	u16 ethertype;
@@ -1958,8 +2132,12 @@ static bool modify_header_match_supporte
 		goto out_ok;
 
 	modify_ip_header = false;
+#ifdef tcf_exts_for_each_action
+	tcf_exts_for_each_action(n, a, exts) {
+#else
 	tcf_exts_to_list(exts, &actions);
 	list_for_each_entry(a, &actions, list) {
+#endif
 		if (!is_tcf_pedit(a))
 			continue;
 
@@ -1984,6 +2162,7 @@ static bool modify_header_match_supporte
 out_ok:
 	return true;
 }
+#endif /* HAVE_TCF_PEDIT_TCFP_KEYS_EX */
 
 static bool actions_match_supported(struct mlx5e_priv *priv,
 				    struct tcf_exts *exts,
@@ -2001,8 +2180,10 @@ static bool actions_match_supported(stru
 	    !(actions & MLX5_FLOW_CONTEXT_ACTION_DECAP))
 		return false;
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (actions & MLX5_FLOW_CONTEXT_ACTION_MOD_HDR)
 		return modify_header_match_supported(&parse_attr->spec, exts);
+#endif
 
 	return true;
 }
@@ -2027,17 +2208,36 @@ static int parse_tc_nic_actions(struct m
 {
 	struct mlx5_nic_flow_attr *attr = flow->nic_attr;
 	const struct tc_action *a;
+#ifdef tcf_exts_for_each_action
+	int i;
+#else
 	LIST_HEAD(actions);
+#endif
 	u32 action = 0;
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	int err;
+#endif
 
+#ifdef HAVE_TCF_EXTS_HAS_ACTIONS
 	if (!tcf_exts_has_actions(exts))
+#else
+	if (tc_no_actions(exts))
+#endif
 		return -EINVAL;
 
 	attr->flow_tag = MLX5_FS_DEFAULT_FLOW_TAG;
 
+#ifdef HAVE_TCF_EXTS_TO_LIST
 	tcf_exts_to_list(exts, &actions);
 	list_for_each_entry(a, &actions, list) {
+#else
+#ifdef tcf_exts_for_each_action
+	tcf_exts_for_each_action(i, a, exts) {
+#else
+	tc_for_each_action(a, exts) {
+#endif
+#endif
+#ifdef HAVE_IS_TCF_GACT_SHOT
 		if (is_tcf_gact_shot(a)) {
 			action |= MLX5_FLOW_CONTEXT_ACTION_DROP;
 			if (MLX5_CAP_FLOWTABLE(priv->mdev,
@@ -2045,7 +2245,9 @@ static int parse_tc_nic_actions(struct m
 				action |= MLX5_FLOW_CONTEXT_ACTION_COUNT;
 			continue;
 		}
+#endif
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 		if (is_tcf_pedit(a)) {
 			err = parse_tc_pedit_action(priv, a, MLX5_FLOW_NAMESPACE_KERNEL,
 						    parse_attr);
@@ -2056,7 +2258,9 @@ static int parse_tc_nic_actions(struct m
 				  MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
 			continue;
 		}
+#endif
 
+#ifdef HAVE_TCA_CSUM_UPDATE_FLAG_IPV4HDR
 		if (is_tcf_csum(a)) {
 			if (csum_offload_supported(priv, action,
 						   tcf_csum_update_flags(a)))
@@ -2064,9 +2268,15 @@ static int parse_tc_nic_actions(struct m
 
 			return -EOPNOTSUPP;
 		}
+#endif
 
 		if (is_tcf_mirred_egress_redirect(a)) {
+#ifdef HAVE_TCF_MIRRED_DEV
 			struct net_device *peer_dev = tcf_mirred_dev(a);
+#else
+			int ifindex = tcf_mirred_ifindex(a);
+			struct net_device *peer_dev = __dev_get_by_index(dev_net(priv->netdev), ifindex);
+#endif
 
 			if (priv->netdev->netdev_ops == peer_dev->netdev_ops &&
 			    same_hw_devs(priv, netdev_priv(peer_dev))) {
@@ -2082,6 +2292,7 @@ static int parse_tc_nic_actions(struct m
 			continue;
 		}
 
+#ifdef HAVE_IS_TCF_SKBEDIT_MARK
 		if (is_tcf_skbedit_mark(a)) {
 			u32 mark = tcf_skbedit_mark(a);
 
@@ -2095,13 +2306,16 @@ static int parse_tc_nic_actions(struct m
 			action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST;
 			continue;
 		}
+#endif
 
 		return -EINVAL;
 	}
 
 	attr->action = action;
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	if (!actions_match_supported(priv, exts, parse_attr, flow))
 		return -EOPNOTSUPP;
+#endif
 
 	return 0;
 }
@@ -2110,12 +2324,17 @@ static struct net_device *mlx5_upper_lag
 {
         struct net_device *upper = netdev_master_upper_dev_get(uplink_dev);
 
-        if (upper && netif_is_lag_master(upper))
-                return upper;
-        else
-                return NULL;
+#if defined(HAVE_LAG_TX_TYPE) || defined(MLX_USE_LAG_COMPAT)
+	if (upper && netif_is_lag_master(upper))
+#else
+	if (upper && netif_is_bond_master(upper))
+#endif
+		return upper;
+	else
+		return NULL;
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 static inline int cmp_encap_info(struct ip_tunnel_key *a,
 				 struct ip_tunnel_key *b)
 {
@@ -2175,6 +2394,7 @@ static int mlx5e_route_lookup_ipv4(struc
 	*out_n = n;
 	return 0;
 }
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
 static bool is_merged_eswitch_dev(struct mlx5e_priv *priv,
 				  struct net_device *peer_netdev)
@@ -2190,6 +2410,8 @@ static bool is_merged_eswitch_dev(struct
 		(peer_priv->mdev->priv.eswitch->mode == SRIOV_OFFLOADS));
 }
 
+#ifdef HAVE_TCF_TUNNEL_INFO
+#ifdef __IPV6_SUPPORT__
 static int mlx5e_route_lookup_ipv6(struct mlx5e_priv *priv,
 				   struct net_device *mirred_dev,
 				   struct net_device **out_dev,
@@ -2240,6 +2462,7 @@ static int mlx5e_route_lookup_ipv6(struc
 	*out_n = n;
 	return 0;
 }
+#endif
 
 static void gen_vxlan_header_ipv4(struct net_device *out_dev,
 				  char buf[], int encap_size,
@@ -2274,6 +2497,7 @@ static void gen_vxlan_header_ipv4(struct
 	vxh->vx_vni = vxlan_vni_field(vx_vni);
 }
 
+#ifdef __IPV6_SUPPORT__
 static void gen_vxlan_header_ipv6(struct net_device *out_dev,
 				  char buf[], int encap_size,
 				  unsigned char h_dest[ETH_ALEN],
@@ -2305,6 +2529,7 @@ static void gen_vxlan_header_ipv6(struct
 	vxh->vx_flags = VXLAN_HF_VNI;
 	vxh->vx_vni = vxlan_vni_field(vx_vni);
 }
+#endif
 
 static int mlx5e_create_encap_header_ipv4(struct mlx5e_priv *priv,
 					  struct net_device *mirred_dev,
@@ -2413,6 +2638,7 @@ out:
 	return err;
 }
 
+#ifdef __IPV6_SUPPORT__
 static int mlx5e_create_encap_header_ipv6(struct mlx5e_priv *priv,
 					  struct net_device *mirred_dev,
 					  struct mlx5e_encap_entry *e)
@@ -2521,6 +2747,7 @@ out:
 		neigh_release(n);
 	return err;
 }
+#endif
 
 static int mlx5e_attach_encap(struct mlx5e_priv *priv,
 			      struct ip_tunnel_info *tun_info,
@@ -2586,8 +2813,13 @@ vxlan_encap_offload_err:
 
 	if (family == AF_INET)
 		err = mlx5e_create_encap_header_ipv4(priv, mirred_dev, e);
+#ifdef __IPV6_SUPPORT__
 	else if (family == AF_INET6)
 		err = mlx5e_create_encap_header_ipv6(priv, mirred_dev, e);
+#else
+	else
+		err = -EOPNOTSUPP;
+#endif
 
 	if (err && err != -EAGAIN)
 		goto out_err;
@@ -2608,33 +2840,68 @@ out_err:
 	kfree(e);
 	return err;
 }
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
 static int parse_tc_fdb_actions(struct mlx5e_priv *priv, struct tcf_exts *exts,
 				struct mlx5e_tc_flow_parse_attr *parse_attr,
+#ifdef HAVE_TCF_TUNNEL_INFO
 				struct mlx5e_tc_flow *flow)
+#else
+				struct mlx5_esw_flow_attr *attr)
+#endif
 {
+#ifdef HAVE_TCF_TUNNEL_INFO
 	struct mlx5_esw_flow_attr *attr = flow->esw_attr;
+#endif
 	struct mlx5e_rep_priv *rpriv = priv->ppriv;
+#ifdef HAVE_TCF_TUNNEL_INFO
+#ifndef CONFIG_COMPAT_TCF_TUNNEL_KEY_MOD
 	struct ip_tunnel_info *info = NULL;
+#else
+	struct ip_tunnel_info info_compat;
+	struct ip_tunnel_info *info = &info_compat;
+#endif
+#endif
 	const struct tc_action *a;
+#ifdef tcf_exts_for_each_action
+	int i;
+#else
 	LIST_HEAD(actions);
+#endif
+#ifdef HAVE_TCF_TUNNEL_INFO
 	bool encap = false;
+#endif
 	u32 action = 0;
 
+#ifdef HAVE_TCF_EXTS_HAS_ACTIONS
 	if (!tcf_exts_has_actions(exts))
+#else
+	if (tc_no_actions(exts))
+#endif
 		return -EINVAL;
 
 	attr->in_rep = rpriv->rep;
 	attr->in_mdev = priv->mdev;
 
+#ifdef HAVE_TCF_EXTS_TO_LIST
 	tcf_exts_to_list(exts, &actions);
 	list_for_each_entry(a, &actions, list) {
+#else
+#ifdef tcf_exts_for_each_action
+	tcf_exts_for_each_action(i, a, exts) {
+#else
+	tc_for_each_action(a, exts) {
+#endif
+#endif
+#ifdef HAVE_IS_TCF_GACT_SHOT
 		if (is_tcf_gact_shot(a)) {
 			action |= MLX5_FLOW_CONTEXT_ACTION_DROP |
 				  MLX5_FLOW_CONTEXT_ACTION_COUNT;
 			continue;
 		}
+#endif
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 		if (is_tcf_pedit(a)) {
 			int err;
 
@@ -2647,7 +2914,9 @@ static int parse_tc_fdb_actions(struct m
 			attr->mirror_count = attr->out_count;
 			continue;
 		}
+#endif
 
+#ifdef HAVE_TCA_CSUM_UPDATE_FLAG_IPV4HDR
 		if (is_tcf_csum(a)) {
 			if (csum_offload_supported(priv, action,
 						   tcf_csum_update_flags(a)))
@@ -2655,12 +2924,18 @@ static int parse_tc_fdb_actions(struct m
 
 			return -EOPNOTSUPP;
 		}
+#endif
 
 		if (is_tcf_mirred_egress_redirect(a) || is_tcf_mirred_egress_mirror(a)) {
 			struct mlx5e_priv *out_priv;
 			struct net_device *out_dev;
 
+#ifdef HAVE_TCF_MIRRED_DEV
 			out_dev = tcf_mirred_dev(a);
+#else
+			int ifindex = tcf_mirred_ifindex(a);
+			out_dev = __dev_get_by_index(dev_net(priv->netdev), ifindex);
+#endif
 
 			if (attr->out_count >= MLX5_MAX_FLOW_FWD_VPORTS) {
 				pr_err("can't support more than %d output ports, can't offload forwarding\n",
@@ -2684,8 +2959,13 @@ static int parse_tc_fdb_actions(struct m
 				rpriv = out_priv->ppriv;
 				attr->out_rep[attr->out_count] = rpriv->rep;
 				attr->out_mdev[attr->out_count++] = out_priv->mdev;
+#ifdef HAVE_TCF_TUNNEL_INFO
 			} else if (encap) {
+#ifdef HAVE_TCF_MIRRED_DEV
 				parse_attr->mirred_ifindex = out_dev->ifindex;
+#else
+				parse_attr->mirred_ifindex = ifindex;
+#endif
 				parse_attr->tun_info = *info;
 				attr->parse_attr = parse_attr;
 				action |= MLX5_FLOW_CONTEXT_ACTION_PACKET_REFORMAT |
@@ -2701,7 +2981,11 @@ static int parse_tc_fdb_actions(struct m
 		}
 
 		if (is_tcf_tunnel_set(a)) {
+#if !defined(CONFIG_COMPAT_TCF_TUNNEL_KEY_MOD) || defined (CONFIG_COMPAT_KERNEL_4_9)
 			info = tcf_tunnel_info(a);
+#else
+			tcf_tunnel_info_compat(a, info);
+#endif
 			if (info)
 				encap = true;
 			else
@@ -2709,7 +2993,21 @@ static int parse_tc_fdb_actions(struct m
 			attr->mirror_count = attr->out_count;
 			continue;
 		}
+#else /* HAVE_TCF_TUNNEL_INFO */
+			} else {
+				pr_err("devices %s %s not on same switch HW, can't offload forwarding\n",
+				       priv->netdev->name, out_dev->name);
+				return -EINVAL;
+			}
+			action |= MLX5_FLOW_CONTEXT_ACTION_FWD_DEST |
+				  MLX5_FLOW_CONTEXT_ACTION_COUNT;
+			out_priv = netdev_priv(out_dev);
+			attr->out_rep[attr->out_count++] = out_priv->ppriv;
+			continue;
+		}
+#endif /* HAVE_TCF_TUNNEL_INFO */
 
+#ifdef HAVE_IS_TCF_VLAN
 		if (is_tcf_vlan(a)) {
 			if (tcf_vlan_action(a) == TCA_VLAN_ACT_POP) {
 				action |= MLX5_FLOW_CONTEXT_ACTION_VLAN_POP;
@@ -2732,17 +3030,22 @@ static int parse_tc_fdb_actions(struct m
 			continue;
 		}
 
+#endif
+#ifdef HAVE_TCF_TUNNEL_INFO
 		if (is_tcf_tunnel_release(a)) {
 			action |= MLX5_FLOW_CONTEXT_ACTION_DECAP;
 			continue;
 		}
+#endif
 
 		return -EINVAL;
 	}
 
 	attr->action = action;
+#ifdef HAVE_TCF_TUNNEL_INFO
 	if (!actions_match_supported(priv, exts, parse_attr, flow))
 		return -EOPNOTSUPP;
+#endif
 
 	if (attr->out_count > 1 && !mlx5_esw_has_fwd_fdb(priv->mdev)) {
 		netdev_warn_once(priv->netdev, "current firmware doesn't support split rule for port mirroring\n");
@@ -2761,10 +3064,13 @@ static void get_flags(int flags, u8 *flo
 {
 	u8 __flow_flags = 0;
 
+#if !(defined(HAVE_NDO_SETUP_TC_4_PARAMS) || defined(HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX))
+	/* relevant for the new ndo */
 	if (flags & MLX5E_TC_INGRESS)
 		__flow_flags |= MLX5E_TC_FLOW_INGRESS;
 	if (flags & MLX5E_TC_EGRESS)
 		__flow_flags |= MLX5E_TC_FLOW_EGRESS;
+#endif
 
 	*flow_flags = __flow_flags;
 }
@@ -2843,7 +3149,11 @@ __mlx5e_add_fdb_flow(struct mlx5e_priv *
 	if (err)
 		goto out;
 
+#ifdef HAVE_TCF_TUNNEL_INFO
 	err = parse_tc_fdb_actions(priv, f->exts, parse_attr, flow);
+#else
+	err = parse_tc_fdb_actions(priv, f->exts, parse_attr, flow->esw_attr);
+#endif
 	if (err)
 		goto err_free;
 
@@ -3027,16 +3337,23 @@ err_free:
 out:
 	return err;
 }
+#ifdef CONFIG_COMPAT_CLS_FLOWER_MOD
+EXPORT_SYMBOL(mlx5e_configure_flower);
+#endif
 
 #define DIRECTION_MASK (MLX5E_TC_INGRESS | MLX5E_TC_EGRESS)
 #define FLOW_DIRECTION_MASK (MLX5E_TC_FLOW_INGRESS | MLX5E_TC_FLOW_EGRESS)
 
 static bool same_flow_direction(struct mlx5e_tc_flow *flow, int flags)
 {
+#if !(defined(HAVE_NDO_SETUP_TC_4_PARAMS) || defined(HAVE_NDO_SETUP_TC_TAKES_CHAIN_INDEX))
 	if ((flow->flags & FLOW_DIRECTION_MASK) == (flags & DIRECTION_MASK))
 		return true;
 
 	return false;
+#else
+	return true;
+#endif
 }
 
 int mlx5e_delete_flower(struct mlx5e_priv *priv,
@@ -3057,13 +3374,21 @@ int mlx5e_delete_flower(struct mlx5e_pri
 
 	return 0;
 }
+#ifdef CONFIG_COMPAT_CLS_FLOWER_MOD
+EXPORT_SYMBOL(mlx5e_delete_flower);
+#endif
 
+#ifdef HAVE_TC_CLSFLOWER_STATS
 int mlx5e_stats_flower(struct mlx5e_priv *priv,
 		       struct tc_cls_flower_offload *f, int flags)
 {
 	struct rhashtable *tc_ht = get_tc_ht(priv);
 	struct mlx5e_tc_flow *flow;
 	struct mlx5_fc *counter;
+#ifndef HAVE_TCF_EXTS_STATS_UPDATE
+	struct tc_action *a;
+	LIST_HEAD(actions);
+#endif
 	u64 bytes;
 	u64 packets;
 	u64 lastuse;
@@ -3096,21 +3421,58 @@ int mlx5e_stats_flower(struct mlx5e_priv
 	}
 
 
+#ifdef HAVE_TCF_EXTS_STATS_UPDATE
 	tcf_exts_stats_update(f->exts, bytes, packets, lastuse);
+#else
+	preempt_disable();
+
+#ifdef HAVE_TCF_EXTS_TO_LIST
+	tcf_exts_to_list(f->exts, &actions);
+	list_for_each_entry(a, &actions, list)
+#else
+	tc_for_each_action(a, f->exts)
+#endif
+#ifdef HAVE_TCF_ACTION_STATS_UPDATE
+	tcf_action_stats_update(a, bytes, packets, lastuse);
+#else
+	{
+		struct tcf_act_hdr *h = a->priv;
+
+		spin_lock(&h->tcf_lock);
+		h->tcf_tm.lastuse = max_t(u64, h->tcf_tm.lastuse, lastuse);
+		h->tcf_bstats.bytes += bytes;
+		h->tcf_bstats.packets += packets;
+		spin_unlock(&h->tcf_lock);
+	}
+#endif
+	preempt_enable();
+#endif
 
 	return 0;
 }
+#ifdef CONFIG_COMPAT_CLS_FLOWER_MOD
+EXPORT_SYMBOL(mlx5e_stats_flower);
+#endif
+#endif
+#endif /* HAVE_TC_FLOWER_OFFLOAD */
 
 int mlx5e_tc_nic_init(struct mlx5e_priv *priv)
 {
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 	struct mlx5e_tc_table *tc = &priv->fs.tc;
 
+#ifdef HAVE_TCF_PEDIT_TCFP_KEYS_EX
 	hash_init(tc->mod_hdr_tbl);
+#endif
 	hash_init(tc->hairpin_tbl);
 
 	return rhashtable_init(&tc->ht, &tc_ht_params);
+#else
+	return 0;
+#endif
 }
 
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 static void _mlx5e_tc_del_flow(void *ptr, void *arg)
 {
 	struct mlx5e_tc_flow *flow = ptr;
@@ -3119,9 +3481,11 @@ static void _mlx5e_tc_del_flow(void *ptr
 	mlx5e_tc_del_flow(priv, flow);
 	kfree(flow);
 }
+#endif
 
 void mlx5e_tc_nic_cleanup(struct mlx5e_priv *priv)
 {
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 	struct mlx5e_tc_table *tc = &priv->fs.tc;
 
 	rhashtable_free_and_destroy(&tc->ht, _mlx5e_tc_del_flow, NULL);
@@ -3130,21 +3494,30 @@ void mlx5e_tc_nic_cleanup(struct mlx5e_p
 		mlx5_destroy_flow_table(tc->t);
 		tc->t = NULL;
 	}
+#endif
 }
 
 int mlx5e_tc_esw_init(struct rhashtable *tc_ht)
 {
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 	return rhashtable_init(tc_ht, &tc_ht_params);
+#else
+	return 0;
+#endif
 }
 
 void mlx5e_tc_esw_cleanup(struct rhashtable *tc_ht)
 {
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 	rhashtable_free_and_destroy(tc_ht, _mlx5e_tc_del_flow, NULL);
+#endif
 }
 
+#ifdef HAVE_TC_FLOWER_OFFLOAD
 int mlx5e_tc_num_filters(struct mlx5e_priv *priv)
 {
 	struct rhashtable *tc_ht = get_tc_ht(priv);
 
 	return atomic_read(&tc_ht->nelems);
 }
+#endif
